{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe7581a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c3dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Selenium version 4.1.3\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import wget\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import urllib.request # version 1.26.9\n",
    "import requests # version 2.25.1\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d714ac2",
   "metadata": {},
   "source": [
    "Before beginning, please ensure you have [webdriver](https://chromedriver.chromium.org/downloads) (for chrome) or [geckodriver](https://github.com/mozilla/geckodriver/releases) (for firefox), additional drivers for browsers like Safari and Edge can be found [here](https://selenium-python.readthedocs.io/installation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f3a14",
   "metadata": {},
   "source": [
    "## Launching browser and accessing Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c1bfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 101.0.4951\n",
      "Get LATEST chromedriver version for 101.0.4951 google-chrome\n",
      "Driver [C:\\Users\\User\\.wdm\\drivers\\chromedriver\\win32\\101.0.4951.41\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Set URL for browser to visit\n",
    "url= \"https://www.instagram.com/\"\n",
    "# Download and Install webdriver chrome on machine, if no existing found\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# Launch Chrome window and visit given URL\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cc1b1",
   "metadata": {},
   "source": [
    "## Logging in\n",
    "**Please note**: it is always best to avoid using your personal Instagram account when web scraping.     \n",
    "\n",
    "Ideally you want to use a dummy account, not associated with your name or personal email. That way, even if Instagram detects you and labels you as a bot - it doesn't affect your personal account and you don't lose it as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179bac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to instagram\n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='username']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='password']\")))\n",
    "username.clear()\n",
    "password.clear()\n",
    "username.send_keys(\"wei_jie_n\") # Input your own username\n",
    "password.send_keys(\"17Q29r97\") # input your own password\n",
    "login = driver.find_element(by=By.CSS_SELECTOR, value=\"button[type='submit']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811036d",
   "metadata": {},
   "source": [
    "## Auto Click popup notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59801b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto clicks not now for popups asking to turn notifications\n",
    "time.sleep(random.randint(3,5))\n",
    "save = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/section/main/div/div/div/div/button'))).click()\n",
    "alert = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()\n",
    "# alert2 = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffdb2cd",
   "metadata": {},
   "source": [
    "## Enter keyword in searchbox and proceed to first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Searchbox find and clear\n",
    "# searchbox = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//input[@placeholder='Search']\")))\n",
    "# searchbox.clear()\n",
    "\n",
    "# # Input keyword and hit enter\n",
    "# keyword = \"HERE\" # 'HERE' can be a hashtag or a profile, replace with your own \n",
    "# searchbox.send_keys(keyword)\n",
    "# time.sleep(random.randint(3,5)) # Wait 5 seconds\n",
    "# searchbox.send_keys(Keys.ENTER)\n",
    "# searchbox.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb4bd3",
   "metadata": {},
   "source": [
    "## Scroll to bottom of page to get earliest post\n",
    "In order to save time and not have readers of this notebook run through the entire process, I have saved the output from running the two code blocks below into an output file named `posts.txt`, which contains the unique link for every post for the target account scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6961f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts = [] # empty list to store all posts from an account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ada7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Auto-scroll to the Bottom of the Page, scraping links for each thumbnail as we scroll along\n",
    "# # Will take awhile for pages with many posts, an account with 700+ posts took about 1.5mins to finish scrolling\n",
    "# match=False\n",
    "# scrolldown = 0\n",
    "# while(match==False):\n",
    "#     last_count = scrolldown\n",
    "#     time.sleep(random.randint(3,5)) # 3 seconds to allow loading, play around with value if you have slower connection speed\n",
    "#     scrolldown = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var scrolldown=document.body.scrollHeight;return scrolldown;\")\n",
    "#     # scroll to current bottom of page, will prompt instagram to load older posts\n",
    "#     links = driver.find_elements(by=By.TAG_NAME, value='a')\n",
    "#     linkshref = []\n",
    "#     for l in links:\n",
    "#         try:\n",
    "#             linkshref.append(l.get_attribute('href'))\n",
    "#         except:\n",
    "#             continue  # to workaround errant links that disappear after scrolling happens\n",
    "#     postslinks = [l for l in linkshref if '/p/' in l and l not in posts]\n",
    "#     posts.extend(postslinks)\n",
    "#     if last_count==scrolldown: #stop once we reached the bottom of all posts of account\n",
    "#         match=True\n",
    "        \n",
    "# print(len(posts)) # added print(len(posts)) to verify that links from a given instagram account is scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path= r'C:\\Users\\User\\Desktop\\GA DSI\\Capstone\\assets\\data\\raw_data'\n",
    "# file_name = 'posts.txt'\n",
    "# completename = os.path.join(path, file_name)\n",
    "# # Save individuallly scraped posts link to prevent multiple runs, potentially flagging our account as a bot\n",
    "# with open(completename, 'w') as output_file:\n",
    "#     for post in posts:\n",
    "#         output_file.write(post + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5e6ae",
   "metadata": {},
   "source": [
    "## Retrieve img/video from instagram's CDN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ceed48",
   "metadata": {},
   "source": [
    "Code below when ran will retrieve each link saved in the `posts.txt` file, access each individual link in order to obtain the `img_link` for each post, this `img_link` is the source image from Instagram's content distribution network, which gives us the highest quality image as opposed to the compressed one's in the thumbnail.\n",
    "\n",
    "Again for the sake of convenience, we have saved all the `img_link`s obtained into a separate output file named `images.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "214a8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../assets/data/raw_data/posts.txt', 'r') as txt_file:\n",
    "    posts = txt_file.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a215dd1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04a84495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []\n",
    "for post in posts:\n",
    "    driver.get(post)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(random.randint(5,10))\n",
    "    try:\n",
    "        img_link = soup.find_all('img', {'class': 'FFVAD'})\n",
    "        img_link = img_link[0]['src']\n",
    "        images.append(img_link)\n",
    "    except IndexError:\n",
    "        continue\n",
    "    except KeyError:\n",
    "        continue\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e6fe278",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= r'C:\\Users\\User\\Desktop\\GA DSI\\Capstone\\assets\\data\\raw_data'\n",
    "file_name = 'images.txt'\n",
    "completename = os.path.join(path, file_name)\n",
    "# Save individuallly scraped posts link to prevent multiple runs, potentially flagging our account as a bot\n",
    "with open(completename, 'w') as output_file:\n",
    "    for image in images:\n",
    "        output_file.write(image + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f5ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../assets/data/raw_data/images.txt', 'r') as txt_file:\n",
    "    images = txt_file.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a7dd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60add5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists\n"
     ]
    }
   ],
   "source": [
    "# Specifiy download path for storing scraped media files\n",
    "if os.path.isdir(path) == True: # Check if path specified exists\n",
    "    print(\"Path exists\")\n",
    "else:\n",
    "    os.mkdir(path)  # Create directories if path does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "677d751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scraped images in specified path\n",
    "counter = 0\n",
    "for image in images:\n",
    "    time.sleep(random.randint(3,5))\n",
    "    urllib.request.urlretrieve(image, os.path.join(path,'{}{}.jpg'.format('image',str(counter))))\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
